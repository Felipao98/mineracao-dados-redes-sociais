# AnÃ¡lise Multifacetada de Comunidades Online no Reddit

Este repositÃ³rio apresenta uma anÃ¡lise de dados completa de uma comunidade online, demonstrando um pipeline que integra **KDD (Descoberta de Conhecimento em Bases de Dados)**, **Processamento de Linguagem Natural (PLN)** e **AnÃ¡lise de Redes Sociais (SNA)**. A partir de dados do subreddit `r/faculdadeBR`, a anÃ¡lise mapeia a estrutura de interaÃ§Ãµes dos usuÃ¡rios, identifica comunidades e caracteriza o foco temÃ¡tico de cada grupo, revelando as "bolhas" de discussÃ£o sobre o tema "TCC".

## âœ¨ Habilidades Demonstradas

Este projeto destaca competÃªncias prÃ¡ticas nas seguintes Ã¡reas de CiÃªncia de Dados:

* **Coleta de Dados via API:**
    * ExtraÃ§Ã£o de dados complexos (posts e comentÃ¡rios em Ã¡rvore) do Reddit utilizando a biblioteca `PRAW`.

* **AnÃ¡lise ExploratÃ³ria de Dados (EDA):**
    * ManipulaÃ§Ã£o, limpeza e enriquecimento de dados com `Pandas`.
    * CriaÃ§Ã£o de visualizaÃ§Ãµes para anÃ¡lise de distribuiÃ§Ã£o e correlaÃ§Ã£o com `Matplotlib` e `Seaborn`.

* **Machine Learning (NÃ£o Supervisionado):**
    * **Clustering:** AplicaÃ§Ã£o do algoritmo **K-Means** (`Scikit-learn`) para agrupar dados numÃ©ricos e textuais.
    * **DetecÃ§Ã£o de Comunidades:** Uso do **mÃ©todo de Louvain** para identificar grupos em redes complexas.

* **Processamento de Linguagem Natural (PLN):**
    * TÃ©cnicas de limpeza e normalizaÃ§Ã£o de texto nÃ£o estruturado com expressÃµes regulares (`re`).
    * Uso de `NLTK` para tratamento de *stopwords*.
    * VetorizaÃ§Ã£o de texto com a tÃ©cnica **TF-IDF**, incluindo a captura de contexto com n-grams.
    * **Modelagem de TÃ³picos** para caracterizaÃ§Ã£o de corpus textuais.

* **AnÃ¡lise de Redes Sociais (SNA):**
    * ConstruÃ§Ã£o, manipulaÃ§Ã£o e anÃ¡lise de grafos de interaÃ§Ã£o social com `NetworkX`.
    * VisualizaÃ§Ã£o de redes para apresentar a topologia e as comunidades.

## ğŸ“‚ Estrutura do Projeto e Jornada AnalÃ­tica

Os scripts neste repositÃ³rio representam uma jornada analÃ­tica evolutiva, onde cada um aprofunda a investigaÃ§Ã£o sobre o mesmo conjunto de dados, seguindo uma progressÃ£o lÃ³gica:

* **`1_caracterizacao.py`:** O ponto de partida. Este script foca na **Coleta, EstruturaÃ§Ã£o e AnÃ¡lise ExploratÃ³ria de Dados (EDA)**. Ele coleta os dados brutos, os organiza em um formato estruturado e realiza a engenharia de features (como `hour_of_day`, `selftext_length`), caracterizando o dataset inicial.

* **`2_kdd.py`:** A primeira abordagem de mineraÃ§Ã£o. Utilizando os dados estruturados e as features criadas no passo anterior, este script aplica o processo de **KDD (Descoberta de Conhecimento em Bases de Dados)** sobre os **metadados** das postagens (score, nÃºmero de comentÃ¡rios), usando K-Means para encontrar padrÃµes de engajamento.

* **`3_text_mining.py`:** A segunda abordagem foca no **conteÃºdo textual**. Este script aplica tÃ©cnicas de PLN para limpar o texto, vetorizÃ¡-lo com TF-IDF e, novamente com K-Means, realizar uma **modelagem de tÃ³picos** para descobrir "o que" estÃ¡ sendo discutido.

* **`4_comunidade.py`:** O script final e mais avanÃ§ado, que integra os conceitos anteriores. Ele eleva a anÃ¡lise para o nÃ­vel de **rede social**, coletando as **interaÃ§Ãµes** entre usuÃ¡rios. Com `NetworkX` e o mÃ©todo de Louvain, ele identifica as comunidades ("quem" fala com "quem") e as caracteriza tematicamente, respondendo "sobre o que cada comunidade conversa".

## ğŸš€ Como Executar

Siga os passos abaixo para replicar a anÃ¡lise principal (SNA).

### 1. PrÃ©-requisitos
* Python 3.8 ou superior
* Credenciais de desenvolvedor para a API do Reddit ([link para criar](https://www.reddit.com/prefs/apps))

### 2. InstalaÃ§Ã£o
Clone este repositÃ³rio e instale as dependÃªncias a partir do arquivo `requirements.txt`.
```bash
git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
cd seu-repositorio
pip install -r requirements.txt
```
*(**Nota:** Para gerar o arquivo `requirements.txt`, execute `pip freeze > requirements.txt` no seu ambiente virtual).*

### 3. ConfiguraÃ§Ã£o
No script `comunidade.py` (ou em um arquivo de configuraÃ§Ã£o), insira suas credenciais da API do Reddit:
```python
client_id = 'SEU_CLIENT_ID'
client_secret = 'SEU_CLIENT_SECRET'
user_agent = 'script:analise-comunidades:v1 (by u/SEU_USUARIO_REDDIG)'
```

### 4. ExecuÃ§Ã£o
Execute o script principal para rodar o pipeline completo de anÃ¡lise de redes sociais. Os resultados, incluindo a visualizaÃ§Ã£o do grafo e a anÃ¡lise textual das comunidades, serÃ£o exibidos na saÃ­da.
```bash
python comunidade.py
```

## ğŸ“ˆ Principais Achados
* A anÃ¡lise da rede revelou a existÃªncia de **mÃºltiplas comunidades** com perfis de interaÃ§Ã£o distintos.
* A caracterizaÃ§Ã£o temÃ¡tica mostrou que diferentes comunidades se especializam em diferentes tipos de discussÃ£o, como **grupos de apoio emocional**, **nichos de debate tÃ©cnico** por Ã¡rea de estudo e **redes de ajuda prÃ¡tica**.
* A integraÃ§Ã£o das trÃªs abordagens (KDD, PLN e SNA) forneceu uma visÃ£o muito mais rica e completa da dinÃ¢mica da comunidade do que qualquer uma das tÃ©cnicas isoladamente.

## ğŸ‘¨â€ğŸ’» Autor

Projeto desenvolvido por **Luis Felipe Marques Silva**  
ğŸ“Œ Estudante de CiÃªncia da ComputaÃ§Ã£o - UFSJ  

ğŸ”— [LinkedIn](https://linkedin.com/in/luisfelipemsilva) â€¢ [GitHub](https://github.com/Felipao98)
